{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from gsplat.sh import spherical_harmonics\n",
    "from internal.models.gaussian_model_simplified import GaussianModelSimplified\n",
    "from internal.renderers.gsplat_renderer import GSPlatRenderer\n",
    "from internal.renderers.gsplat_hit_pixel_count_renderer import GSplatHitPixelCountRenderer\n",
    "from internal.dataparsers.colmap_dataparser import ColmapDataParser\n",
    "from internal.configs.dataset import ColmapParams\n",
    "from internal.utils.sh_utils import RGB2SH\n",
    "from internal.utils.gaussian_model_loader import GaussianModelLoader\n",
    "from internal.utils.light_gaussian import get_count_and_score, calculate_v_imp_score, get_prune_mask"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.autograd.set_grad_enabled(False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "253d162b56dc1681",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "partition_base_dir = os.path.expanduser(\"~/data/image_set/JNUCar_undistorted/colmap/drone/dense_max_2048/0/partitions-threshold_0.2/\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58439cf23b16df07",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataparser_outputs = ColmapDataParser(\n",
    "    os.path.join(partition_base_dir, \"..\"),\n",
    "    output_path=os.getcwd(),\n",
    "    global_rank=0,\n",
    "    params=ColmapParams(\n",
    "        appearance_groups=\"appearance_image_dedicated\",\n",
    "        eval_step=32\n",
    "    ),\n",
    ").get_outputs()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da461e704fd3d02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_name_to_camera_idx = {}\n",
    "for idx, name in enumerate(dataparser_outputs.train_set.image_names):\n",
    "    image_name_to_camera_idx[name] = idx\n",
    "len(image_name_to_camera_idx)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acd30869a8b7c042",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_cameras_by_image_list(image_list: list):\n",
    "    cameras = []\n",
    "    for i in image_list:\n",
    "        cameras.append(dataparser_outputs.train_set.cameras[image_name_to_camera_idx[i]])\n",
    "    return cameras"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924272b43abdc20",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "partitions = torch.load(os.path.join(partition_base_dir, \"partitions.pt\"),\n",
    "                        map_location=\"cpu\")\n",
    "\n",
    "orientation_transformation = partitions[\"orientation_transformation\"]\n",
    "\n",
    "model_paths = []\n",
    "for idx, i in enumerate(partitions[\"ids\"]):\n",
    "    if len(partitions[\"image_indices\"][idx]) < 32:\n",
    "        continue\n",
    "    model_paths.append((i, os.path.join(\n",
    "        \"../outputs/JNUAerial-0526/\",\n",
    "        f\"P_{i[0]:03d}_{i[1]:03d}.txt\")))\n",
    "partitions.keys(), model_paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb88dc2829a6b0c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "partition_id_to_index = {i: idx for idx, i in enumerate(partitions[\"ids\"])}\n",
    "partition_id_to_index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1e8bd2b3bdeee05",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "n_sh_degrees = 0\n",
    "\n",
    "DICT_KEY_PREFIX = \"gaussian_model._\"\n",
    "\n",
    "prune_percent = 0.6\n",
    "\n",
    "n_gaussians_before_pruning = 0\n",
    "n_gaussians_after_pruning = 0\n",
    "\n",
    "with tqdm(model_paths) as t:\n",
    "    for i in t:\n",
    "        if i[0] != (0, 0):\n",
    "            continue\n",
    "            \n",
    "        partition_id = i[0]\n",
    "        model_output_path = i[1]\n",
    "            \n",
    "        partition_xy = partitions[\"xys\"][partition_id_to_index[i[0]]]\n",
    "        load_file = GaussianModelLoader.search_load_file(i[1])\n",
    "        t.set_description(f\"{partition_xy}: {load_file}\")\n",
    "        ckpt = torch.load(load_file, map_location=device)\n",
    "        xyz = ckpt[\"state_dict\"][\"gaussian_model._xyz\"]\n",
    "        reoriented_xyz = xyz @ orientation_transformation[:3, :3].T\n",
    "        # include min bound, exclude max bound\n",
    "        is_in_partition = torch.logical_and(torch.ge(reoriented_xyz[:, :2], partition_xy),\n",
    "                                            torch.lt(reoriented_xyz[:, :2], partition_xy + 2 * partitions[\"radius\"]))\n",
    "        is_in_partition = torch.logical_and(is_in_partition[:, 0], is_in_partition[:, 1])\n",
    "        \n",
    "        # get Gaussians located in partition to construct a new state_dict\n",
    "        state_dict = {}\n",
    "        for i in ckpt[\"state_dict\"]:\n",
    "            if i.startswith(DICT_KEY_PREFIX):\n",
    "                state_dict[i] = ckpt[\"state_dict\"][i][is_in_partition]\n",
    "        # construct Gaussian model\n",
    "        gaussian_model = GaussianModelSimplified.construct_from_state_dict(\n",
    "            state_dict,\n",
    "            active_sh_degree=ckpt[\"hyper_parameters\"][\"gaussian\"].sh_degree,\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "        \n",
    "        n_gaussians_before_pruning += gaussian_model.get_xyz.shape[0]\n",
    "        \n",
    "        # get partition image list\n",
    "        with open(os.path.join(model_output_path, \"cameras.json\"), \"r\") as f:\n",
    "            cameras_json = json.load(f)\n",
    "        image_list = [i[\"img_name\"] for i in cameras_json]\n",
    "        # with open(os.path.join(partition_base_dir, f\"{partition_id[0]:03d}_{partition_id[1]:03d}.txt\"), \"r\") as f:\n",
    "        #     for row in f:\n",
    "        #         image_list.append(row.rstrip(\"\\n\"))\n",
    "                \n",
    "        cameras = get_cameras_by_image_list(image_list)\n",
    "    \n",
    "        # calculate scores\n",
    "        hit_camera_count, opacity_score, alpha_score, visibility_score = get_count_and_score(\n",
    "            gaussian_model,\n",
    "            cameras,\n",
    "            anti_aliased=True,\n",
    "        )\n",
    "        \n",
    "        # prune by visibility\n",
    "        # # get prune indices\n",
    "        # visibility_score_close_to_zero = torch.isclose(visibility_score, torch.tensor(0.).to(visibility_score))\n",
    "        # visibility_score_close_to_zero_count = visibility_score_close_to_zero.sum()\n",
    "        # prune_percent = 0.9\n",
    "        # # ignore the Gaussians visibility score close zero\n",
    "        # keep_count = ((visibility_score.shape[0] - visibility_score_close_to_zero_count) * (1 - prune_percent)).to(torch.int)\n",
    "        # # get the indices (in partition) to be preserved\n",
    "        # visibility_score_sorted = torch.sort(visibility_score, descending=True)\n",
    "        # local_indices_to_preserved = visibility_score_sorted.indices[:keep_count].cpu()\n",
    "        \n",
    "        # prune by opacity\n",
    "        v_imp_score = calculate_v_imp_score(gaussian_model.get_scaling, opacity_score, 0.1)\n",
    "        prune_mask = get_prune_mask(prune_percent, v_imp_score)\n",
    "        local_indices_to_preserved = (~prune_mask).nonzero().squeeze(-1).cpu()\n",
    "        \n",
    "        # prune local state_dict\n",
    "        for i in state_dict:\n",
    "            state_dict[i] = state_dict[i][local_indices_to_preserved]\n",
    "        # # the indices (in partition) to be pruned\n",
    "        # local_indices_to_prune = visibility_score_sorted.indices[keep_count:]\n",
    "        # is_in_partition_indices = is_in_partition.nonzero().squeeze(-1)\n",
    "        # gaussian_indices_to_prune = is_in_partition_indices[local_indices_to_prune.to(device=is_in_partition_indices.device)]\n",
    "        # \n",
    "        # # convert prune indices to preserve mask\n",
    "        # preserve_mask = torch.ones_like(is_in_partition, dtype=torch.bool)\n",
    "        # preserve_mask[gaussian_indices_to_prune] = False\n",
    "        \n",
    "        # update state_dict of checkpoint\n",
    "        \"\"\"\n",
    "        [NOTE]\n",
    "        The codes related to the `static part` below have not been released yet.\n",
    "        So, rather than move some Gaussian to `static part`, you should prune the `state_dict`, `optimizer_states` and `gaussian_model_extra_state_dict` of `ckpt` according to the mask `local_indices_to_preserved`.\n",
    "        \"\"\"\n",
    "        for i in state_dict:\n",
    "            # move those Gaussian outside the partition to static part, which will not be optimized during finetune\n",
    "            static_gaussian_property_key = f\"static_{i}\"\n",
    "            static_gaussian_property = ckpt[\"state_dict\"][i][~is_in_partition]\n",
    "            if static_gaussian_property_key in ckpt[\"state_dict\"]:\n",
    "                original_static_gaussian_num = ckpt[\"state_dict\"][static_gaussian_property_key].shape[0]\n",
    "                new_static_gaussian_num = static_gaussian_property.shape[0]\n",
    "                static_gaussian_property = torch.concat([\n",
    "                    ckpt[\"state_dict\"][static_gaussian_property_key],\n",
    "                    static_gaussian_property,\n",
    "                ], dim=0)\n",
    "                print(f\"#{partition_id}: {original_static_gaussian_num} static Gaussians exists, merge with {new_static_gaussian_num} new static Gaussians, total {static_gaussian_property.shape[0]} after merging\")\n",
    "            ckpt[\"state_dict\"][static_gaussian_property_key] = static_gaussian_property\n",
    "            # make optimizable Gaussians only contains those locating in partition\n",
    "            ckpt[\"state_dict\"][i] = state_dict[i]\n",
    "    \n",
    "        # prune optimizer state\n",
    "        for i in ckpt[\"optimizer_states\"][0][\"state\"]:\n",
    "            for j in [\"exp_avg\", \"exp_avg_sq\"]:\n",
    "                ckpt[\"optimizer_states\"][0][\"state\"][i][j] = ckpt[\"optimizer_states\"][0][\"state\"][i][j][is_in_partition][local_indices_to_preserved]\n",
    "        \n",
    "        # prune extra state_dict\n",
    "        for i in [\"max_radii2D\", \"xyz_gradient_accum\", \"denom\"]:\n",
    "            ckpt[\"gaussian_model_extra_state_dict\"][i] = ckpt[\"gaussian_model_extra_state_dict\"][i][is_in_partition][local_indices_to_preserved]\n",
    "            \n",
    "        n_gaussians_after_pruning += local_indices_to_preserved.shape[0]\n",
    "        \n",
    "        # save checkpoint\n",
    "        checkpoint_save_dir = os.path.join(model_output_path, \"pruned_checkpoints\")\n",
    "        os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
    "        torch.save(ckpt, os.path.join(checkpoint_save_dir, f\"latest-opacity_pruned-{prune_percent}.ckpt\"))\n",
    "        \n",
    "f\"{n_gaussians_after_pruning} / {n_gaussians_before_pruning}\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4970f80b12cb03d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
